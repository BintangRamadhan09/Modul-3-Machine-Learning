{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ya = [0,0,0,0,0,1,1,1,1,1]\n",
    "yp = [0,0,0,1,1,0,0,1,1,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- | prediksi 0 | prediksi 1\n",
    "- | - | -\n",
    "__Actual 0__ | 3 | 2\n",
    "__Actual 1__ | 2 | 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 2],\n",
       "       [2, 3]], dtype=int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm= confusion_matrix(ya,yp)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediksi 0</th>\n",
       "      <th>prediksi 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Actual 0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Actual 1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          prediksi 0  prediksi 1\n",
       "Actual 0           3           2\n",
       "Actual 1           2           3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(cm,columns=['prediksi 0','prediksi 1'],index=['Actual 0','Actual 1'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "positional argument follows keyword argument (<ipython-input-5-727bda9fca05>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-5-727bda9fca05>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    sb.heatmap(df,annot=True,annot_kws('size'=30))\u001b[0m\n\u001b[1;37m                            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m positional argument follows keyword argument\n"
     ]
    }
   ],
   "source": [
    "# plot confusion matrix\n",
    "sb.heatmap(df,annot=True,annot_kws('size'=30))\n",
    "plt.ylim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "x = np.arange(1,11)\n",
    "y = np.array([0,0,0,0,1,0,1,0,1,1])\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "model.fit(x.reshape(-1,1),y)\n",
    "\n",
    "# prediksi\n",
    "yp = model.predict(x.reshape(-1,1))\n",
    "yp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- | prediksi 0 | prediksi 1\n",
    "- | - | -\n",
    "__Actual 0__ | 5 | 1\n",
    "__Actual 1__ | 1 | 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm1 = confusion_matrix(y,yp,labels=[0,1])\n",
    "# cm1\n",
    "df1 = pd.DataFrame(cm1,columns=['Pred 0','Pred 1'],index=['Act 0','Act 1'])\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.heatmap(df1,annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "plot_confusion_matrix(model,x.reshape(-1,1),y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "\n",
    "### Evaluation Metrics from Confusion Matrix\n",
    "\n",
    "\n",
    "- __True__    : y prediksi = y aktual\n",
    "\n",
    "- __False__   : y prediksi != y aktual\n",
    "\n",
    "- __Positif__ : model y prediksi = 1\n",
    "\n",
    "- __Negatif__ : model y prediksi = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__True Positive (TP)__: y = 1 & yp = 1\n",
    "\n",
    "__True Negative (TN)__: y = 0 & yp = 0\n",
    "\n",
    "__False Positive (FP)__: y = 0 & yp = 1\n",
    "\n",
    "__False Negative (FN)__: y =1 & yp = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual \n",
    "tp = 3; tn = 5; fp = 1; fn = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn confusion matrix ravel\n",
    "tn, fp, fn, tp = confusion_matrix(y,yp).ravel()\n",
    "tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. __Accuracy__: seberapa sering model kita memprediksi dengan benar?\n",
    "\n",
    "    ( tp + tn ) / total_data = (3 + 5) / 10 = 0.8 = 80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Akurasi',((tp+tn)/len(y)) *100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. __Inaccuracy / Error Rate / Missclassification Rate__ : \n",
    "    \n",
    "    seberapa sering model kita memprediksi dengan salah?\n",
    "    \n",
    "    (fp+fn) / total_data = (1 + 1) / 10 = 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Error Rate',((fp+fn)/len(y))*100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. __TP Rate / Sensitivity / Recall (positif)__\n",
    "\n",
    "    if yes = 1, seberapa sering model prediksi yp = 1?\n",
    "    \n",
    "    tp / total_actual_1 = 3 / 4 = 0.75 = 75%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. __FP Rate__ : If yes = 0, seberapa sering model prediksi yp = 1\n",
    "   \n",
    "   fp / total_actual_0 = 1 / 6 = 0.167 = 16.7%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. __TN Rate / Specificity / Selectivity / Recall (Negative)__ : \n",
    "    \n",
    "\n",
    "    >< FP Rate = if y = 0 , Seberapa sering yp = 0\n",
    "    \n",
    "    1 - FP Rate = 1 - 0.167 = 0.88 = 88%\n",
    "    \n",
    "    tn / total_actual_0 = 5 / 6 = 0.83%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. __FN Rate__ : if y = 1 , seberapa sering model yp = 0\n",
    "\n",
    "    \n",
    "    >< TP Rate : 1 - TP Rate = 1 - 0.75 = 0.25 = 25%\n",
    "    \n",
    "    fn / total_actual_1 = 1 / 4 = 0.25 = 25%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. __Precision__ : if yp = 1, seberapa sering benar?\n",
    "\n",
    "    tp / total_predict_1 = tp / (tp + fp) = 3 / 4 = 75%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. __Prevalence__ : seberapa banyak actual 1?\n",
    "\n",
    "    total_actual_1 / total_data = 4 / 10 = 40%\n",
    "    \n",
    "    (tp + fn) / total data = ( 3 + 1 ) / 10 = 40%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. __Null Error Rate__ : Seberapa banyak actual = 0\n",
    "\n",
    "    1 - prevalence = 1 - 0.4 = 0.6 = 60%\n",
    "    \n",
    "    (fp + tn) / total data = (5 + 1) / 10 = 0.6 = 60%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. __F1 Score__ : Rata-rata harmoni precision (+) & recall (+)\n",
    "    \n",
    "    2 * ( (precisionP * recallP) / (precisionP + recallP) )\n",
    "    \n",
    "    2 * ((0.75 * 0.75) / (0.75 + 0.75))\n",
    "    \n",
    "    = 2 * (0.5625 / 1.5)\n",
    "    \n",
    "    = 2 * 0.375 = 0.75 = 75 %\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. __Balanced Accuracy__\n",
    "\n",
    "    Recall(+) + Recall(-) / 2 = (0.75 + 0.83) / 2 = 1.58 / 2 = 0.79 = 79%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Akurasi',((tp+tn)/len(y)) *100,'%')\n",
    "print('Error Rate',((fp+fn)/len(y))*100,'%')\n",
    "print('TPr / Recall(+):',tp/(tp+fn))\n",
    "print('FP rate :', fp/(fp+tn))\n",
    "print('TNr / Recall(-):',tn/(fp+tn))\n",
    "print('FN rate:', fn/(tp+fn))\n",
    "print('Precision(+):', tp/(tp+fp))\n",
    "print('Precision(-):', tn/(tn+fn))\n",
    "print('Prevalence:', (tp+fn)/len(y))\n",
    "print('Null error rate:',(fp + tn)/len(y))\n",
    "print('F1 score:',2*(((tp/(tp+fp)) * (tp/(tp+fn))) / ((tp/(tp+fp)) + (tp/(tp+fp)))))\n",
    "print('bACC:',((tp/(tp+fn)) + (tn/(fp+tn))) / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
