{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Sarah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Sarah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Sarah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Sarah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Sarah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>Sarah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>Zaenab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Sarah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>Zaenab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Zaenab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>Sarah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>Sarah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>Zaenab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>Sarah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>Zaenab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>Zaenab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>Zaenab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>Zaenab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>Zaenab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>Zaenab</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     x       y\n",
       "0    1   Sarah\n",
       "1    2   Sarah\n",
       "2    3   Sarah\n",
       "3    4   Sarah\n",
       "4    5   Sarah\n",
       "5    6   Sarah\n",
       "6    7  Zaenab\n",
       "7    8   Sarah\n",
       "8    9  Zaenab\n",
       "9   10  Zaenab\n",
       "10  11   Sarah\n",
       "11  12   Sarah\n",
       "12  13  Zaenab\n",
       "13  14   Sarah\n",
       "14  15  Zaenab\n",
       "15  16  Zaenab\n",
       "16  17  Zaenab\n",
       "17  18  Zaenab\n",
       "18  19  Zaenab\n",
       "19  20  Zaenab"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "        'x':np.arange(1,21),\n",
    "#         'y':np.array([0,0,0,0,0,0,1,0,1,1,0,0,1,0,1,1,1,1,1,1])\n",
    "        'y':np.array(['Sarah','Sarah','Sarah','Sarah','Sarah','Sarah','Zaenab','Sarah','Zaenab','Zaenab',\n",
    "                     'Sarah','Sarah','Zaenab','Sarah','Zaenab','Zaenab','Zaenab','Zaenab','Zaenab','Zaenab'])\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sarah', 'Sarah', 'Sarah', 'Sarah', 'Sarah', 'Sarah', 'Zaenab', 'Sarah', 'Zaenab', 'Zaenab', 'Sarah', 'Sarah', 'Zaenab', 'Sarah', 'Zaenab', 'Zaenab', 'Zaenab', 'Zaenab', 'Zaenab', 'Zaenab']\n",
      "['Sarah', 'Sarah', 'Sarah', 'Sarah', 'Sarah', 'Sarah', 'Sarah', 'Sarah', 'Sarah', 'Sarah', 'Zaenab', 'Zaenab', 'Zaenab', 'Zaenab', 'Zaenab', 'Zaenab', 'Zaenab', 'Zaenab', 'Zaenab', 'Zaenab']\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(solver='lbfgs')\n",
    "model.fit(df[['x']],df['y'])\n",
    "\n",
    "y = (df['y']).tolist()\n",
    "yp = model.predict(df[['x']]).tolist()\n",
    "print(y)\n",
    "print(yp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Sarah = 0, Zaenab = 1\n",
    "\n",
    "- | pred Sarah | pred Zaenab\n",
    "- | - | -\n",
    "__actual Sarah__ | TN | FP\n",
    "__actual Zaenab__ | FN | TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['yp'] = yp\n",
    "# df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TP\n",
    "tp = len(df[df['y'] == 'Zaenab'][df['yp'] == 'Zaenab'].index)\n",
    "fp = len(df[df['y'] == 'Sarah'][df['yp'] == 'Zaenab'].index)\n",
    "tn = len(df[df['y'] == 'Sarah'][df['yp'] == 'Sarah'].index)\n",
    "fn = len(df[df['y'] == 'Zaenab'][df['yp'] == 'Sarah'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "3\n",
      "7\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(tp)\n",
    "print(fp)\n",
    "print(tn)\n",
    "print(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi 70.0 %\n",
      "Error Rate 30.0 %\n",
      "TPr / Recall(+): 0.7\n",
      "FP rate : 0.3\n",
      "TNr / Recall(-): 0.7\n",
      "FN rate: 0.3\n",
      "Precision(+): 0.7\n",
      "Precision(-): 0.7\n",
      "Prevalence: 0.5\n",
      "Null error rate: 0.5\n",
      "bACC: 0.7\n",
      "F1 score: 0.7\n"
     ]
    }
   ],
   "source": [
    "print('Akurasi',((tp+tn)/len(y)) *100,'%')\n",
    "print('Error Rate',((fp+fn)/len(y))*100,'%')\n",
    "print('TPr / Recall(+):',tp/(tp+fn))\n",
    "print('FP rate :', fp/(fp+tn))\n",
    "print('TNr / Recall(-):',tn/(fp+tn))\n",
    "print('FN rate:', fn/(tp+fn))\n",
    "print('Precision(+):', tp/(tp+fp))\n",
    "print('Precision(-):', tn/(tn+fn))\n",
    "print('Prevalence:', (tp+fn)/len(y))\n",
    "print('Null error rate:',(fp + tn)/len(y))\n",
    "# print('F1 score:',2*(((tp/(tp+fp)) * (tp/(tp+fn))) / ((tp/(tp+fp)) + (tp/(tp+fp)))))\n",
    "print('bACC:',((tp/(tp+fn)) + (tn/(fp+tn))) / 2)\n",
    "\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp+fn)\n",
    "print('F1 score:', 2*((precision*recall) / (precision + recall)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7, 3],\n",
       "       [3, 7]], dtype=int64)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(df['y'],df['yp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 3, 3, 7)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp,fn,fp,tn = confusion_matrix(df['y'],df['yp']).ravel()\n",
    "tp,fn,fp,tn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.score: 0.7\n",
      "accuracy_score: 0.7\n",
      "Error Rate: 0.30000000000000004\n"
     ]
    }
   ],
   "source": [
    "print('model.score:',model.score(df[['x']],df['y']))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "acs = accuracy_score\n",
    "print('accuracy_score:',acs(df['y'],df['yp']))\n",
    "print('Error Rate:', 1-acs(df['y'],df['yp']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score(+): 0.7\n",
      "Recall Score(-): 0.7\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "rs = recall_score\n",
    "print('Recall Score(+):',rs(df['y'],df['yp'],pos_label='Zaenab'))\n",
    "print('Recall Score(-):',rs(df['y'],df['yp'],pos_label='Sarah'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision(+): 0.7\n",
      "Precision(-): 0.7\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "ps= precision_score\n",
    "print('Precision(+):',ps(df['y'],df['yp'],pos_label='Zaenab'))\n",
    "print('Precision(-):',ps(df['y'],df['yp'],pos_label='Sarah'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Balanced Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bAcc: 0.7\n"
     ]
    }
   ],
   "source": [
    "# (recall(+) + recall(-)) / 2\n",
    "# rclP = tp /(tp+fn)\n",
    "# rclN = tn/(fp+tn)\n",
    "# bAcc = (rclP + rclN) /2 \n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "bas = balanced_accuracy_score\n",
    "print('bAcc:',bas(df['y'],df['yp']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score(+): 0.7\n",
      "F1 Score(-): 0.7\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print('F1 Score(+):',f1_score(df['y'],df['yp'],pos_label='Zaenab'))\n",
    "print('F1 Score(-):',f1_score(df['y'],df['yp'],pos_label='Sarah'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7, 0.7, 0.7, None)\n",
      "(0.7, 0.7, 0.7, None)\n",
      "(0.7, 0.7, 0.7, None)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "prfs = precision_recall_fscore_support\n",
    "prfs(df['y'],df['yp'])\n",
    "print(prfs(df['y'],df['yp'],average='micro'))\n",
    "print(prfs(df['y'],df['yp'],average='macro'))\n",
    "print(prfs(df['y'],df['yp'],average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Sarah       0.70      0.70      0.70        10\n",
      "      Zaenab       0.70      0.70      0.70        10\n",
      "\n",
      "    accuracy                           0.70        20\n",
      "   macro avg       0.70      0.70      0.70        20\n",
      "weighted avg       0.70      0.70      0.70        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df['y'],df['yp']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# precision\n",
    "precSa = tn /(tn+fn)\n",
    "precZa = tp/(tp+fp)\n",
    "\n",
    "precMacro = (precZa + precSa) / 2\n",
    "precWeighted = ((precSa*1) + (precZa *1)) /(1+1)\n",
    "precMacro,precWeighted\n",
    "\n",
    "precMicro = (tn+fp) / (tn+fn+tp+fp)\n",
    "precMicro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "za = ['Kucing','Anjing','Gajah','Kucing','Anjing','Gajah']\n",
    "zp = ['Kucing','Kucing','Gajah','Kucing','Kucing','Gajah']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 2],\n",
       "       [0, 2, 0],\n",
       "       [0, 0, 2]], dtype=int64)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm= confusion_matrix(za,zp)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Anjing       0.00      0.00      0.00         2\n",
      "       Gajah       1.00      1.00      1.00         2\n",
      "      Kucing       0.50      1.00      0.67         2\n",
      "\n",
      "    accuracy                           0.67         6\n",
      "   macro avg       0.50      0.67      0.56         6\n",
      "weighted avg       0.50      0.67      0.56         6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(za,zp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
